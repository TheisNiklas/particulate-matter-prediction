{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing_temp import prep_window_generator\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "import neptune\n",
    "from neptune.integrations.tensorflow_keras import NeptuneCallback\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_generator = prep_window_generator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "class Params:\n",
    "    lstm_layer_count: int\n",
    "    lstm_sizes: List[int]\n",
    "    lstm_bidirectional: bool\n",
    "    lstm_return_sequences: bool\n",
    "    pooling_type: str\n",
    "    kernel_sizes: List[int]\n",
    "    dense_layer_count: int\n",
    "    conv_layer_sizes: List[int]\n",
    "    dropout: float\n",
    "    input_width: int\n",
    "    label_width: int\n",
    "    batch_size: int\n",
    "    loss_function: str\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        lstm_layer_count=1,\n",
    "        lstm_sizes=[32],\n",
    "        lstm_bidirectional=False,\n",
    "        lstm_return_sequences=False,\n",
    "        pooling_type=\"MaxPooling\",\n",
    "        kernel_sizes=[5, 5, 5],\n",
    "        dense_layer_count=1,\n",
    "        dense_layer_sizes=[512],\n",
    "        conv_layer_sizes=[128, 256, 256],\n",
    "        dropout=0.2,\n",
    "        input_width=7 * 24,\n",
    "        label_width=1 * 24,\n",
    "        batch_size=32,\n",
    "        loss_function=\"mse\",\n",
    "    ):\n",
    "        self.lstm_layer_count = lstm_layer_count\n",
    "        self.lstm_sizes = lstm_sizes\n",
    "        self.lstm_bidirectional = lstm_bidirectional\n",
    "        self.lstm_return_sequences = lstm_return_sequences\n",
    "        self.pooling_type = pooling_type\n",
    "        self.kernel_sizes = kernel_sizes\n",
    "        self.dense_layer_count = dense_layer_count\n",
    "        self.dense_layer_sizes = dense_layer_sizes\n",
    "        self.conv_layer_sizes = conv_layer_sizes\n",
    "        self.dropout = dropout\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.batch_size = batch_size\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def to_name(self, epochs: int):\n",
    "        name = \"cnn_\"\n",
    "        if self.lstm_bidirectional:\n",
    "            name += \"bi\"\n",
    "        name += \"lstm_\"\n",
    "        name += str(int(self.input_width / 24)) + \"days_history_\"\n",
    "        name += str(int(self.label_width / 24)) + \"days_pred_\"\n",
    "        name += str(epochs) + \"_epochs\"\n",
    "        if self.lstm_layer_count != 1:\n",
    "            name += \"_\" + str(self.lstm_layer_count) + \"lstm-layer\"\n",
    "            name += \"_\" + \",\".join([str(i) for i in self.lstm_sizes])\n",
    "        if self.lstm_return_sequences:\n",
    "            name += \"_ret-seq\"\n",
    "        if self.pooling_type != \"MaxPooling\":\n",
    "            name += \"_\" + \"pooling-\" + self.pooling_type\n",
    "        if self.dropout != 0.2:\n",
    "            name += \"_\" + \"dropout-0-\" + str(int(self.dropout * 10))\n",
    "\n",
    "        return name\n",
    "\n",
    "    def to_dict(self):\n",
    "        self_dict = self.__dict__\n",
    "        for key, value in self_dict.items():\n",
    "            if isinstance(value, list):\n",
    "                self_dict[key] = str(value)\n",
    "        return self_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_model(params: Params):\n",
    "    num_features = 1\n",
    "    init_kernel_size = params.kernel_sizes[0]\n",
    "    cnn_lstm_model = tf.keras.models.Sequential()\n",
    "    # Shape [batch, time, features] => [batch, CONV_WIDTH, features]\n",
    "    cnn_lstm_model.add(tf.keras.layers.Normalization())\n",
    "    cnn_lstm_model.add(tf.keras.layers.Lambda(lambda x: x[:, -init_kernel_size:, :]))\n",
    "    # Shape => [batch, 1, conv_units]\n",
    "    cnn_lstm_model.add(\n",
    "        tf.keras.layers.Conv1D(\n",
    "            params.conv_layer_sizes[0], activation=\"relu\", kernel_size=params.kernel_sizes[0], padding=\"same\"\n",
    "        )\n",
    "    )\n",
    "    if params.pooling_type == \"MaxPooling\":\n",
    "        cnn_lstm_model.add(tf.keras.layers.MaxPooling1D())\n",
    "    else:\n",
    "        cnn_lstm_model.add(tf.keras.layers.AveragePooling1D())\n",
    "    cnn_lstm_model.add(tf.keras.layers.BatchNormalization())  # TODO: useful to put it here?\n",
    "    cnn_lstm_model.add(\n",
    "        tf.keras.layers.Conv1D(\n",
    "            params.conv_layer_sizes[1], activation=\"relu\", kernel_size=params.kernel_sizes[1], padding=\"same\"\n",
    "        )\n",
    "    )\n",
    "    if params.pooling_type == \"MaxPooling\":\n",
    "        cnn_lstm_model.add(tf.keras.layers.MaxPooling1D())\n",
    "    else:\n",
    "        cnn_lstm_model.add(tf.keras.layers.AveragePooling1D())\n",
    "    cnn_lstm_model.add(tf.keras.layers.BatchNormalization())  # TODO: useful to put it here?\n",
    "    cnn_lstm_model.add(\n",
    "        tf.keras.layers.Conv1D(\n",
    "            params.conv_layer_sizes[2], activation=\"relu\", kernel_size=params.kernel_sizes[2], padding=\"same\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    cnn_lstm_model.add(tf.keras.layers.Reshape((-1, 256)))\n",
    "    # LSTM\n",
    "    if params.lstm_layer_count == 2:\n",
    "        lstm_layer1 = tf.keras.layers.LSTM(params.lstm_sizes[0], return_sequences=True)\n",
    "        if params.lstm_bidirectional:\n",
    "            cnn_lstm_model.add(tf.keras.layers.Bidirectional(lstm_layer1))\n",
    "        else:\n",
    "            cnn_lstm_model.add(lstm_layer1)\n",
    "\n",
    "    lstm_layer2 = tf.keras.layers.LSTM(params.lstm_sizes[-1], return_sequences=params.lstm_return_sequences)\n",
    "    if params.lstm_bidirectional:\n",
    "        cnn_lstm_model.add(tf.keras.layers.Bidirectional(lstm_layer2))\n",
    "    else:\n",
    "        cnn_lstm_model.add(lstm_layer2)\n",
    "\n",
    "    for i in range(params.dense_layer_count):\n",
    "        cnn_lstm_model.add(tf.keras.layers.Dense(params.dense_layer_sizes[i]))\n",
    "        cnn_lstm_model.add(tf.keras.layers.Dropout(params.dropout))\n",
    "\n",
    "    cnn_lstm_model.add(\n",
    "        tf.keras.layers.Dense(params.label_width * num_features, kernel_initializer=tf.initializers.zeros())\n",
    "    )\n",
    "    # Shape => [batch, out_steps, features] -> for each prediction step one neuron\n",
    "    cnn_lstm_model.add(tf.keras.layers.Reshape([params.label_width, num_features]))\n",
    "    return cnn_lstm_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "\n",
    "run_params: Dict[str, Params] = {}\n",
    "run_params[\"base_run\"] = Params()\n",
    "run_params[\"lstm_size_64\"] = Params(lstm_sizes=[64])\n",
    "run_params[\"two_lstm_size_32\"] = Params(lstm_layer_count=2, lstm_sizes=[32, 32])\n",
    "run_params[\"two_lstm_size_64\"] = Params(lstm_layer_count=2, lstm_sizes=[64, 64])\n",
    "run_params[\"bidirectional_lstm\"] = Params(lstm_bidirectional=True)\n",
    "run_params[\"bidirectional_two_lstm\"] = Params(lstm_bidirectional=True, lstm_layer_count=2, lstm_sizes=[32, 32])\n",
    "run_params[\"average_pooling\"] = Params(pooling_type=\"AveragePooling\")\n",
    "run_params[\"kernel_sizes_adjusted_to_hours\"] = Params(kernel_sizes=[24, 12, 6])\n",
    "run_params[\"two_dense_layer\"] = Params(dense_layer_count=2, dense_layer_sizes=[512, 256])\n",
    "run_params[\"dropout_0.4\"] = Params(dropout=0.3)\n",
    "run_params[\"dropout_0.4\"] = Params(dropout=0.4)\n",
    "run_params[\"dropout_0.5\"] = Params(dropout=0.5)\n",
    "run_params[\"dropout_0.6\"] = Params(dropout=0.6)\n",
    "run_params[\"loss_huber\"] = Params(loss_function=\"huber\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://app.neptune.ai/data-mining-team2/initial-model-tests/e/IMT-10\n",
      "Epoch 1/5\n",
      "728/728 [==============================] - 15s 17ms/step - loss: 393.6563 - mean_absolute_error: 13.0762 - val_loss: 323.5807 - val_mean_absolute_error: 12.0086\n",
      "Epoch 2/5\n",
      "728/728 [==============================] - 12s 16ms/step - loss: 329.2359 - mean_absolute_error: 11.9731 - val_loss: 320.6897 - val_mean_absolute_error: 11.6369\n",
      "Epoch 3/5\n",
      "728/728 [==============================] - 12s 16ms/step - loss: 319.5548 - mean_absolute_error: 11.7887 - val_loss: 315.7220 - val_mean_absolute_error: 12.2315\n",
      "Epoch 4/5\n",
      "728/728 [==============================] - 12s 16ms/step - loss: 313.5499 - mean_absolute_error: 11.6578 - val_loss: 308.0201 - val_mean_absolute_error: 11.2329\n",
      "Epoch 5/5\n",
      "728/728 [==============================] - 13s 17ms/step - loss: 306.0692 - mean_absolute_error: 11.4900 - val_loss: 301.0569 - val_mean_absolute_error: 11.2925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/cnn_lstm_24days_history_3days_pred_50_epochs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/cnn_lstm_24days_history_3days_pred_50_epochs\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "728/728 [==============================] - 10s 13ms/step - loss: 301.7361 - mean_absolute_error: 11.4438 - val_loss: 368.4911 - val_mean_absolute_error: 13.5272\n",
      "Epoch 2/5\n",
      "728/728 [==============================] - 10s 13ms/step - loss: 298.3039 - mean_absolute_error: 11.3692 - val_loss: 308.7127 - val_mean_absolute_error: 11.6110\n",
      "Epoch 3/5\n",
      "728/728 [==============================] - 10s 14ms/step - loss: 293.2456 - mean_absolute_error: 11.2693 - val_loss: 302.9725 - val_mean_absolute_error: 11.1262\n",
      "Epoch 4/5\n",
      "728/728 [==============================] - 9s 12ms/step - loss: 286.9782 - mean_absolute_error: 11.1419 - val_loss: 285.7923 - val_mean_absolute_error: 11.2618\n",
      "Epoch 5/5\n",
      "728/728 [==============================] - 9s 12ms/step - loss: 276.7703 - mean_absolute_error: 10.9067 - val_loss: 281.5990 - val_mean_absolute_error: 10.9524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/cnn_lstm_24days_history_3days_pred_100_epochs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/cnn_lstm_24days_history_3days_pred_100_epochs\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "728/728 [==============================] - 10s 13ms/step - loss: 269.8956 - mean_absolute_error: 10.7645 - val_loss: 276.9345 - val_mean_absolute_error: 10.6493\n",
      "Epoch 2/5\n",
      "728/728 [==============================] - 10s 13ms/step - loss: 265.1469 - mean_absolute_error: 10.6510 - val_loss: 273.9983 - val_mean_absolute_error: 10.7440\n",
      "Epoch 3/5\n",
      "728/728 [==============================] - 10s 13ms/step - loss: 262.2274 - mean_absolute_error: 10.5805 - val_loss: 276.2790 - val_mean_absolute_error: 10.6843\n",
      "Epoch 4/5\n",
      "728/728 [==============================] - 10s 14ms/step - loss: 255.5335 - mean_absolute_error: 10.4451 - val_loss: 270.8358 - val_mean_absolute_error: 10.5595\n",
      "Epoch 5/5\n",
      "728/728 [==============================] - 10s 14ms/step - loss: 252.5242 - mean_absolute_error: 10.3804 - val_loss: 273.3356 - val_mean_absolute_error: 10.6793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/cnn_lstm_24days_history_3days_pred_150_epochs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/cnn_lstm_24days_history_3days_pred_150_epochs\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "728/728 [==============================] - 12s 17ms/step - loss: 246.6264 - mean_absolute_error: 10.2622 - val_loss: 293.9261 - val_mean_absolute_error: 11.0571\n",
      "Epoch 2/5\n",
      "728/728 [==============================] - 12s 17ms/step - loss: 241.9731 - mean_absolute_error: 10.1712 - val_loss: 256.5767 - val_mean_absolute_error: 10.4647\n",
      "Epoch 3/5\n",
      "728/728 [==============================] - 12s 17ms/step - loss: 235.2334 - mean_absolute_error: 10.0363 - val_loss: 262.5401 - val_mean_absolute_error: 10.4293\n",
      "Epoch 4/5\n",
      "728/728 [==============================] - 12s 17ms/step - loss: 231.3583 - mean_absolute_error: 9.9663 - val_loss: 249.4443 - val_mean_absolute_error: 10.1677\n",
      "Epoch 5/5\n",
      "728/728 [==============================] - 12s 17ms/step - loss: 223.0656 - mean_absolute_error: 9.8070 - val_loss: 253.5987 - val_mean_absolute_error: 10.1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, lstm_cell_6_layer_call_fn, lstm_cell_6_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/cnn_lstm_24days_history_3days_pred_200_epochs\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/cnn_lstm_24days_history_3days_pred_200_epochs\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shutting down background jobs, please wait a moment...\n",
      "Done!\n",
      "Waiting for the remaining 3 operations to synchronize with Neptune. Do not kill this process.\n",
      "All 3 operations synced, thanks for waiting!\n",
      "Explore the metadata in the Neptune app:\n",
      "https://app.neptune.ai/data-mining-team2/initial-model-tests/e/IMT-10/metadata\n"
     ]
    }
   ],
   "source": [
    "for run_id, params in run_params.items():\n",
    "    model = init_model(params)\n",
    "\n",
    "    loss = tf.keras.losses.MeanSquaredError()\n",
    "    if params.loss_function == \"huber\":\n",
    "        loss = tf.keras.losses.huber\n",
    "    model.compile(loss=loss, optimizer=\"Adam\", metrics=[tf.keras.metrics.MeanAbsoluteError()])\n",
    "\n",
    "    name = params.to_name(100)\n",
    "    append_index = 0\n",
    "    while os.path.exists(\"../models/\" + name):\n",
    "        append_index += 1\n",
    "    if append_index != 0:\n",
    "        name += \"_\" + str(append_index)\n",
    "\n",
    "    run = neptune.init_run(\n",
    "        project=\"data-mining-team2/initial-model-tests\",\n",
    "        api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiI4Mzg2ZWZmYi05YzRlLTQ3ODYtOWE1NC1mNDM4OTM1ZjNlOTkifQ==\",\n",
    "        custom_run_id=run_id,\n",
    "        name=name,\n",
    "        source_files=[\"./initial_model_tests.ipynb\"],\n",
    "    )\n",
    "\n",
    "    run[\"parameters\"] = params.to_dict()\n",
    "\n",
    "    neptune_cbk = NeptuneCallback(run=run, base_namespace=\"training\")\n",
    "\n",
    "    try:\n",
    "        for epoch_count_factor in range(1, 5):\n",
    "            epoch_count = 50 * epoch_count_factor\n",
    "            history = model.fit(\n",
    "                window_generator.train,\n",
    "                epochs=50,\n",
    "                validation_data=window_generator.val,\n",
    "                callbacks=[neptune_cbk],\n",
    "            )\n",
    "\n",
    "            eval_metrics = model.evaluate(window_generator.test, verbose=0)\n",
    "            for j, metric in enumerate(eval_metrics):\n",
    "                run[f\"eval/epoch_{epoch_count}/{model.metrics_names[j]}\"] = metric\n",
    "\n",
    "            name = params.to_name(epoch_count)\n",
    "            temp_name = name\n",
    "            append_index = 0\n",
    "            while os.path.exists(\"../models/\" + temp_name):\n",
    "                append_index += 1\n",
    "                temp_name = name + \"_\" + str(append_index)\n",
    "            if append_index != 0:\n",
    "                name += \"_\" + str(append_index)\n",
    "\n",
    "            model.save(\"../models/\" + name, include_optimizer=False)\n",
    "\n",
    "            run[\"model_names/\" + str(epoch_count) + \"epochs\"] = name\n",
    "    except:\n",
    "        pass\n",
    "    run.stop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
